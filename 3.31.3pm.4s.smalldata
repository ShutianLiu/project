shutian@shutian-virtual-machine:~$ cd Desktop/Project/code
shutian@shutian-virtual-machine:~/Desktop/Project/code$ python danet-softmax-small.py
| epoch   1 |     1/    3 batches | ms/batch 2500.02 | loss 96072.62 |
| epoch   1 |     2/    3 batches | ms/batch 2732.90 | loss 103095.00 |
| epoch   1 |     3/    3 batches | ms/batch 2632.19 | loss 94400.84 |
---------------------------------------------------------------------------------------------------
    | end of training epoch   1 | time:  7.90s | training loss 94400.84 |
    | end of validation epoch   1 | time:  1.28s | validation loss 53309.17 |
---------------------------------------------------------------------------------------------------
      Best training model found.
---------------------------------------------------------------------------------------------------
      Best validation model found and saved.
---------------------------------------------------------------------------------------------------
| epoch   2 |     1/    3 batches | ms/batch 2567.29 | loss 100995.62 |
| epoch   2 |     2/    3 batches | ms/batch 2512.18 | loss 95132.98 |
| epoch   2 |     3/    3 batches | ms/batch 2507.28 | loss 92250.28 |
---------------------------------------------------------------------------------------------------
    | end of training epoch   2 | time:  7.52s | training loss 92250.28 |
    | end of validation epoch   2 | time:  1.32s | validation loss 51942.54 |
---------------------------------------------------------------------------------------------------
      Best training model found.
---------------------------------------------------------------------------------------------------
      Best validation model found and saved.
---------------------------------------------------------------------------------------------------
| epoch   3 |     1/    3 batches | ms/batch 2386.61 | loss 78315.23 |
| epoch   3 |     2/    3 batches | ms/batch 2491.62 | loss 79354.83 |
| epoch   3 |     3/    3 batches | ms/batch 2486.09 | loss 90831.46 |
---------------------------------------------------------------------------------------------------
    | end of training epoch   3 | time:  7.46s | training loss 90831.46 |
    | end of validation epoch   3 | time:  1.33s | validation loss 52306.34 |
---------------------------------------------------------------------------------------------------
      Best training model found.
---------------------------------------------------------------------------------------------------
| epoch   4 |     1/    3 batches | ms/batch 2399.25 | loss 104183.62 |
| epoch   4 |     2/    3 batches | ms/batch 2464.74 | loss 97233.48 |
| epoch   4 |     3/    3 batches | ms/batch 2658.64 | loss 90352.45 |
---------------------------------------------------------------------------------------------------
    | end of training epoch   4 | time:  7.98s | training loss 90352.45 |
    | end of validation epoch   4 | time:  1.30s | validation loss 52076.96 |
---------------------------------------------------------------------------------------------------
      Best training model found.
---------------------------------------------------------------------------------------------------
| epoch   5 |     1/    3 batches | ms/batch 2359.95 | loss 73568.89 |
| epoch   5 |     2/    3 batches | ms/batch 2415.39 | loss 92036.66 |
| epoch   5 |     3/    3 batches | ms/batch 2419.08 | loss 90124.99 |
---------------------------------------------------------------------------------------------------
    | end of training epoch   5 | time:  7.26s | training loss 90124.99 |
    | end of validation epoch   5 | time:  1.24s | validation loss 51768.51 |
---------------------------------------------------------------------------------------------------
      Best training model found.
---------------------------------------------------------------------------------------------------
      Best validation model found and saved.
---------------------------------------------------------------------------------------------------
| epoch   6 |     1/    3 batches | ms/batch 2586.75 | loss 91329.10 |
| epoch   6 |     2/    3 batches | ms/batch 2566.92 | loss 98716.29 |
| epoch   6 |     3/    3 batches | ms/batch 2547.99 | loss 90005.03 |
---------------------------------------------------------------------------------------------------
    | end of training epoch   6 | time:  7.64s | training loss 90005.03 |
    | end of validation epoch   6 | time:  1.32s | validation loss 51600.73 |
---------------------------------------------------------------------------------------------------
      Best training model found.
---------------------------------------------------------------------------------------------------
      Best validation model found and saved.
---------------------------------------------------------------------------------------------------
| epoch   7 |     1/    3 batches | ms/batch 2381.97 | loss 89140.66 |
| epoch   7 |     2/    3 batches | ms/batch 2458.29 | loss 87220.05 |
| epoch   7 |     3/    3 batches | ms/batch 2476.46 | loss 89964.17 |
---------------------------------------------------------------------------------------------------
    | end of training epoch   7 | time:  7.43s | training loss 89964.17 |
    | end of validation epoch   7 | time:  1.28s | validation loss 51564.68 |
---------------------------------------------------------------------------------------------------
      Best training model found.
---------------------------------------------------------------------------------------------------
      Best validation model found and saved.
---------------------------------------------------------------------------------------------------
| epoch   8 |     1/    3 batches | ms/batch 2608.24 | loss 81681.74 |
| epoch   8 |     2/    3 batches | ms/batch 2548.40 | loss 93486.21 |
| epoch   8 |     3/    3 batches | ms/batch 2544.56 | loss 89805.28 |
---------------------------------------------------------------------------------------------------
    | end of training epoch   8 | time:  7.63s | training loss 89805.28 |
    | end of validation epoch   8 | time:  1.42s | validation loss 51555.68 |
---------------------------------------------------------------------------------------------------
      Best training model found.
---------------------------------------------------------------------------------------------------
      Best validation model found and saved.
---------------------------------------------------------------------------------------------------
| epoch   9 |     1/    3 batches | ms/batch 3024.72 | loss 72386.96 |
| epoch   9 |     2/    3 batches | ms/batch 2870.67 | loss 87873.50 |
| epoch   9 |     3/    3 batches | ms/batch 2959.91 | loss 89730.34 |
---------------------------------------------------------------------------------------------------
    | end of training epoch   9 | time:  8.88s | training loss 89730.34 |
    | end of validation epoch   9 | time:  1.37s | validation loss 51489.47 |
---------------------------------------------------------------------------------------------------
      Best training model found.
---------------------------------------------------------------------------------------------------
      Best validation model found and saved.
---------------------------------------------------------------------------------------------------
| epoch  10 |     1/    3 batches | ms/batch 3585.16 | loss 90346.34 |
Variable containing:
(  0  ,.,.) = 
  0.2822  0.2433  0.2317  0.2428
  0.2411  0.2546  0.2583  0.2460
  0.2396  0.2516  0.2554  0.2534
               ⋮                
  0.2479  0.2502  0.2500  0.2519
  0.2447  0.2510  0.2545  0.2499
  0.2540  0.2472  0.2461  0.2527

(  1  ,.,.) = 
  0.1075  0.3099  0.2932  0.2894
  0.2721  0.2423  0.2432  0.2424
  0.3149  0.2255  0.2294  0.2303
               ⋮                
  0.2802  0.2376  0.2405  0.2416
  0.2968  0.2307  0.2362  0.2363
  0.2539  0.2483  0.2475  0.2503

(  2  ,.,.) = 
  0.1691  0.2171  0.3034  0.3105
  0.2649  0.2544  0.2417  0.2391
  0.2823  0.2576  0.2313  0.2288
               ⋮                
  0.2634  0.2535  0.2417  0.2413
  0.2704  0.2557  0.2370  0.2369
  0.2511  0.2489  0.2498  0.2502

(  3  ,.,.) = 
  0.2864  0.2443  0.2541  0.2152
  0.2409  0.2496  0.2513  0.2582
  0.2399  0.2528  0.2479  0.2594
               ⋮                
  0.2468  0.2503  0.2491  0.2538
  0.2427  0.2506  0.2485  0.2582
  0.2508  0.2498  0.2497  0.2497
[torch.FloatTensor of size 4x30000x4]

| epoch  10 |     2/    3 batches | ms/batch 3557.17 | loss 84605.02 |
Variable containing:
(  0  ,.,.) = 
  0.2752  0.3040  0.2873  0.1335
  0.2477  0.2408  0.2435  0.2680
  0.2368  0.2294  0.2350  0.2988
               ⋮                
  0.2416  0.2415  0.2445  0.2725
  0.2397  0.2366  0.2382  0.2855
  0.2488  0.2488  0.2492  0.2532

(  1  ,.,.) = 
  0.2317  0.1937  0.3344  0.2402
  0.2434  0.2560  0.2507  0.2499
  0.2593  0.2663  0.2231  0.2513
               ⋮                
  0.2562  0.2599  0.2331  0.2508
  0.2531  0.2648  0.2310  0.2511
  0.2531  0.2524  0.2437  0.2508

(  2  ,.,.) = 
  0.2666  0.2663  0.2214  0.2457
  0.2499  0.2490  0.2524  0.2487
  0.2450  0.2452  0.2562  0.2536
               ⋮                
  0.2475  0.2463  0.2532  0.2530
  0.2474  0.2451  0.2571  0.2505
  0.2502  0.2484  0.2504  0.2510

(  3  ,.,.) = 
  0.2500  0.2378  0.2244  0.2878
  0.2498  0.2553  0.2572  0.2377
  0.2482  0.2546  0.2590  0.2382
               ⋮                
  0.2496  0.2517  0.2523  0.2464
  0.2504  0.2525  0.2565  0.2407
  0.2496  0.2496  0.2478  0.2530
[torch.FloatTensor of size 4x30000x4]

| epoch  10 |     3/    3 batches | ms/batch 3383.37 | loss 89659.69 |
Variable containing:
(  0  ,.,.) = 
  0.2921  0.2218  0.2428  0.2433
  0.2413  0.2557  0.2518  0.2511
  0.2394  0.2569  0.2527  0.2510
               ⋮                
  0.2464  0.2517  0.2516  0.2503
  0.2406  0.2564  0.2525  0.2506
  0.2517  0.2493  0.2491  0.2499

(  1  ,.,.) = 
  0.2103  0.2885  0.2486  0.2527
  0.2517  0.2461  0.2528  0.2494
  0.2639  0.2376  0.2497  0.2489
               ⋮                
  0.2588  0.2427  0.2479  0.2505
  0.2619  0.2404  0.2490  0.2487
  0.2514  0.2489  0.2474  0.2523

(  2  ,.,.) = 
  0.4716  0.2733  0.1523  0.1028
  0.2323  0.2374  0.2624  0.2679
  0.1919  0.2285  0.2700  0.3097
               ⋮                
  0.2187  0.2414  0.2592  0.2807
  0.2046  0.2327  0.2670  0.2957
  0.2458  0.2516  0.2490  0.2537

(  3  ,.,.) = 
  0.2772  0.2827  0.2334  0.2066
  0.2397  0.2454  0.2473  0.2676
  0.2445  0.2434  0.2556  0.2564
               ⋮                
  0.2487  0.2478  0.2548  0.2488
  0.2420  0.2427  0.2546  0.2607
  0.2528  0.2506  0.2528  0.2437
[torch.FloatTensor of size 4x30000x4]

---------------------------------------------------------------------------------------------------
    | end of training epoch  10 | time: 10.32s | training loss 89659.69 |
    | end of validation epoch  10 | time:  1.33s | validation loss 51523.81 |
---------------------------------------------------------------------------------------------------
      Best training model found.
---------------------------------------------------------------------------------------------------
| epoch  11 |     1/    3 batches | ms/batch 2467.58 | loss 98908.52 |
| epoch  11 |     2/    3 batches | ms/batch 2458.46 | loss 87040.14 |
| epoch  11 |     3/    3 batches | ms/batch 2466.66 | loss 89620.32 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  11 | time:  7.40s | training loss 89620.32 |
    | end of validation epoch  11 | time:  1.32s | validation loss 51562.92 |
---------------------------------------------------------------------------------------------------
      Best training model found.
---------------------------------------------------------------------------------------------------
| epoch  12 |     1/    3 batches | ms/batch 2438.02 | loss 79723.64 |
| epoch  12 |     2/    3 batches | ms/batch 2458.55 | loss 80247.36 |
| epoch  12 |     3/    3 batches | ms/batch 2458.38 | loss 89487.80 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  12 | time:  7.38s | training loss 89487.80 |
    | end of validation epoch  12 | time:  1.32s | validation loss 51744.09 |
---------------------------------------------------------------------------------------------------
      Best training model found.
---------------------------------------------------------------------------------------------------
| epoch  13 |     1/    3 batches | ms/batch 2299.24 | loss 102690.75 |
| epoch  13 |     2/    3 batches | ms/batch 2416.82 | loss 90863.66 |
| epoch  13 |     3/    3 batches | ms/batch 2463.04 | loss 89475.35 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  13 | time:  7.39s | training loss 89475.35 |
    | end of validation epoch  13 | time:  1.39s | validation loss 51599.54 |
---------------------------------------------------------------------------------------------------
      Best training model found.
---------------------------------------------------------------------------------------------------
| epoch  14 |     1/    3 batches | ms/batch 2461.22 | loss 80548.58 |
| epoch  14 |     2/    3 batches | ms/batch 2505.85 | loss 84452.86 |
| epoch  14 |     3/    3 batches | ms/batch 2575.94 | loss 89479.57 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  14 | time:  7.73s | training loss 89479.57 |
    | end of validation epoch  14 | time:  1.34s | validation loss 51709.19 |
---------------------------------------------------------------------------------------------------
| epoch  15 |     1/    3 batches | ms/batch 2472.56 | loss 89832.08 |
| epoch  15 |     2/    3 batches | ms/batch 2513.49 | loss 93761.95 |
| epoch  15 |     3/    3 batches | ms/batch 2584.66 | loss 89471.88 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  15 | time:  7.75s | training loss 89471.88 |
    | end of validation epoch  15 | time:  1.57s | validation loss 51669.73 |
---------------------------------------------------------------------------------------------------
      Best training model found.
---------------------------------------------------------------------------------------------------
| epoch  16 |     1/    3 batches | ms/batch 2940.76 | loss 93104.68 |
| epoch  16 |     2/    3 batches | ms/batch 2771.85 | loss 85732.64 |
| epoch  16 |     3/    3 batches | ms/batch 2878.06 | loss 89379.57 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  16 | time:  8.63s | training loss 89379.57 |
    | end of validation epoch  16 | time:  1.40s | validation loss 51551.62 |
---------------------------------------------------------------------------------------------------
      Best training model found.
---------------------------------------------------------------------------------------------------
| epoch  17 |     1/    3 batches | ms/batch 2875.82 | loss 77508.30 |
| epoch  17 |     2/    3 batches | ms/batch 2760.51 | loss 84510.76 |
| epoch  17 |     3/    3 batches | ms/batch 2743.61 | loss 89346.38 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  17 | time:  8.23s | training loss 89346.38 |
    | end of validation epoch  17 | time:  1.46s | validation loss 51743.73 |
---------------------------------------------------------------------------------------------------
      Best training model found.
---------------------------------------------------------------------------------------------------
| epoch  18 |     1/    3 batches | ms/batch 3636.06 | loss 91248.33 |
| epoch  18 |     2/    3 batches | ms/batch 3358.30 | loss 86048.46 |
| epoch  18 |     3/    3 batches | ms/batch 3360.60 | loss 89352.59 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  18 | time: 10.08s | training loss 89352.59 |
    | end of validation epoch  18 | time:  1.64s | validation loss 51644.20 |
---------------------------------------------------------------------------------------------------
| epoch  19 |     1/    3 batches | ms/batch 3124.55 | loss 77566.30 |
| epoch  19 |     2/    3 batches | ms/batch 3077.81 | loss 90411.20 |
| epoch  19 |     3/    3 batches | ms/batch 3027.54 | loss 89311.52 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  19 | time:  9.08s | training loss 89311.52 |
    | end of validation epoch  19 | time:  1.46s | validation loss 51583.31 |
---------------------------------------------------------------------------------------------------
      Best training model found.
---------------------------------------------------------------------------------------------------
| epoch  20 |     1/    3 batches | ms/batch 2442.99 | loss 100155.45 |
Variable containing:
(  0  ,.,.) = 
  0.1740  0.2445  0.2770  0.3045
  0.2531  0.2396  0.2637  0.2435
  0.2959  0.2423  0.2410  0.2208
               ⋮                
  0.2825  0.2487  0.2388  0.2300
  0.3062  0.2450  0.2316  0.2173
  0.2393  0.2485  0.2538  0.2584

(  1  ,.,.) = 
  0.2935  0.2317  0.2230  0.2519
  0.2348  0.2678  0.2672  0.2301
  0.2313  0.2608  0.2532  0.2548
               ⋮                
  0.2403  0.2574  0.2533  0.2490
  0.2310  0.2594  0.2586  0.2510
  0.2645  0.2419  0.2368  0.2569

(  2  ,.,.) = 
  0.2783  0.2306  0.2405  0.2506
  0.2510  0.2478  0.2570  0.2442
  0.2575  0.2408  0.2589  0.2427
               ⋮                
  0.2527  0.2459  0.2563  0.2451
  0.2415  0.2538  0.2575  0.2472
  0.2573  0.2455  0.2473  0.2498

(  3  ,.,.) = 
  0.1141  0.2878  0.3039  0.2943
  0.2280  0.2734  0.2533  0.2453
  0.2840  0.2460  0.2369  0.2331
               ⋮                
  0.2858  0.2402  0.2389  0.2351
  0.3634  0.2140  0.2097  0.2129
  0.2293  0.2545  0.2559  0.2603
[torch.FloatTensor of size 4x30000x4]

| epoch  20 |     2/    3 batches | ms/batch 2550.79 | loss 87727.47 |
Variable containing:
(  0  ,.,.) = 
  0.4133  0.2997  0.1816  0.1054
  0.2803  0.2322  0.2438  0.2437
  0.2189  0.2337  0.2502  0.2971
               ⋮                
  0.2174  0.2354  0.2563  0.2909
  0.1675  0.2045  0.2626  0.3654
  0.2645  0.2652  0.2422  0.2280

(  1  ,.,.) = 
  0.2707  0.2589  0.2338  0.2367
  0.2512  0.2554  0.2371  0.2563
  0.2425  0.2497  0.2253  0.2824
               ⋮                
  0.2456  0.2475  0.2384  0.2685
  0.2400  0.2419  0.2494  0.2687
  0.2536  0.2482  0.2474  0.2509

(  2  ,.,.) = 
  0.2488  0.2291  0.2101  0.3120
  0.2452  0.2625  0.2701  0.2222
  0.2400  0.2615  0.2705  0.2279
               ⋮                
  0.2456  0.2576  0.2639  0.2330
  0.2464  0.2612  0.2734  0.2190
  0.2495  0.2450  0.2383  0.2672

(  3  ,.,.) = 
  0.2583  0.2002  0.3055  0.2360
  0.2207  0.2420  0.2841  0.2532
  0.2805  0.2482  0.2129  0.2584
               ⋮                
  0.2641  0.2571  0.2236  0.2551
  0.2586  0.2772  0.2056  0.2586
  0.2603  0.2453  0.2452  0.2492
[torch.FloatTensor of size 4x30000x4]

| epoch  20 |     3/    3 batches | ms/batch 2576.38 | loss 89271.25 |
Variable containing:
(  0  ,.,.) = 
  0.3040  0.2403  0.2409  0.2148
  0.2292  0.2556  0.2607  0.2544
  0.2416  0.2653  0.2465  0.2465
               ⋮                
  0.2399  0.2582  0.2483  0.2535
  0.2276  0.2571  0.2493  0.2660
  0.2619  0.2484  0.2477  0.2420

(  1  ,.,.) = 
  0.2634  0.2969  0.2970  0.1427
  0.2629  0.2507  0.2466  0.2399
  0.2336  0.2336  0.2488  0.2840
               ⋮                
  0.2353  0.2369  0.2446  0.2831
  0.2264  0.2184  0.2209  0.3344
  0.2507  0.2563  0.2582  0.2348

(  2  ,.,.) = 
  0.2231  0.2851  0.2612  0.2305
  0.2367  0.2559  0.2484  0.2590
  0.2615  0.2365  0.2393  0.2627
               ⋮                
  0.2614  0.2390  0.2438  0.2558
  0.2703  0.2276  0.2371  0.2650
  0.2484  0.2537  0.2480  0.2499

(  3  ,.,.) = 
  0.2629  0.2587  0.2423  0.2361
  0.2417  0.2663  0.2374  0.2546
  0.2661  0.2796  0.2622  0.1921
               ⋮                
  0.2548  0.2663  0.2579  0.2211
  0.2498  0.2569  0.2643  0.2290
  0.2567  0.2515  0.2546  0.2371
[torch.FloatTensor of size 4x30000x4]

---------------------------------------------------------------------------------------------------
    | end of training epoch  20 | time:  7.88s | training loss 89271.25 |
    | end of validation epoch  20 | time:  1.38s | validation loss 51723.34 |
---------------------------------------------------------------------------------------------------
      Best training model found.
---------------------------------------------------------------------------------------------------
| epoch  21 |     1/    3 batches | ms/batch 2757.15 | loss 82456.09 |
| epoch  21 |     2/    3 batches | ms/batch 2833.46 | loss 81894.79 |
| epoch  21 |     3/    3 batches | ms/batch 2724.97 | loss 89256.27 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  21 | time:  8.18s | training loss 89256.27 |
    | end of validation epoch  21 | time:  1.33s | validation loss 51609.08 |
---------------------------------------------------------------------------------------------------
      Best training model found.
---------------------------------------------------------------------------------------------------
| epoch  22 |     1/    3 batches | ms/batch 2760.26 | loss 99791.82 |
| epoch  22 |     2/    3 batches | ms/batch 2805.08 | loss 95804.92 |
| epoch  22 |     3/    3 batches | ms/batch 2720.41 | loss 89222.00 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  22 | time:  8.16s | training loss 89222.00 |
    | end of validation epoch  22 | time:  1.36s | validation loss 51629.53 |
---------------------------------------------------------------------------------------------------
      Best training model found.
---------------------------------------------------------------------------------------------------
| epoch  23 |     1/    3 batches | ms/batch 3067.32 | loss 92331.56 |
| epoch  23 |     2/    3 batches | ms/batch 2920.48 | loss 83526.17 |
| epoch  23 |     3/    3 batches | ms/batch 2820.75 | loss 89147.09 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  23 | time:  8.46s | training loss 89147.09 |
    | end of validation epoch  23 | time:  1.34s | validation loss 51604.86 |
---------------------------------------------------------------------------------------------------
      Best training model found.
---------------------------------------------------------------------------------------------------
| epoch  24 |     1/    3 batches | ms/batch 2657.48 | loss 95643.87 |
| epoch  24 |     2/    3 batches | ms/batch 2819.62 | loss 95597.50 |
| epoch  24 |     3/    3 batches | ms/batch 2960.25 | loss 89075.20 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  24 | time:  8.88s | training loss 89075.20 |
    | end of validation epoch  24 | time:  1.65s | validation loss 51646.64 |
---------------------------------------------------------------------------------------------------
      Best training model found.
---------------------------------------------------------------------------------------------------
| epoch  25 |     1/    3 batches | ms/batch 2896.28 | loss 103336.70 |
| epoch  25 |     2/    3 batches | ms/batch 3066.91 | loss 86267.26 |
| epoch  25 |     3/    3 batches | ms/batch 3234.24 | loss 89217.34 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  25 | time:  9.70s | training loss 89217.34 |
    | end of validation epoch  25 | time:  2.05s | validation loss 52866.32 |
---------------------------------------------------------------------------------------------------
| epoch  26 |     1/    3 batches | ms/batch 3299.82 | loss 85963.11 |
| epoch  26 |     2/    3 batches | ms/batch 3174.75 | loss 84599.18 |
| epoch  26 |     3/    3 batches | ms/batch 3338.75 | loss 89793.84 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  26 | time: 10.02s | training loss 89793.84 |
    | end of validation epoch  26 | time:  1.78s | validation loss 51506.22 |
---------------------------------------------------------------------------------------------------
| epoch  27 |     1/    3 batches | ms/batch 2453.29 | loss 92090.94 |
| epoch  27 |     2/    3 batches | ms/batch 2506.51 | loss 90115.92 |
| epoch  27 |     3/    3 batches | ms/batch 2513.88 | loss 90069.39 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  27 | time:  7.54s | training loss 90069.39 |
    | end of validation epoch  27 | time:  1.40s | validation loss 51538.17 |
---------------------------------------------------------------------------------------------------
      Learning rate decreased.
---------------------------------------------------------------------------------------------------
| epoch  28 |     1/    3 batches | ms/batch 2452.57 | loss 69405.52 |
| epoch  28 |     2/    3 batches | ms/batch 2478.36 | loss 81819.09 |
| epoch  28 |     3/    3 batches | ms/batch 2632.57 | loss 94555.87 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  28 | time:  7.90s | training loss 94555.87 |
    | end of validation epoch  28 | time:  1.55s | validation loss 52187.23 |
---------------------------------------------------------------------------------------------------
      Learning rate decreased.
---------------------------------------------------------------------------------------------------
| epoch  29 |     1/    3 batches | ms/batch 2936.82 | loss 89990.17 |
| epoch  29 |     2/    3 batches | ms/batch 2874.30 | loss 91974.36 |
| epoch  29 |     3/    3 batches | ms/batch 2718.57 | loss 91617.61 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  29 | time:  8.16s | training loss 91617.61 |
    | end of validation epoch  29 | time:  1.27s | validation loss 51864.18 |
---------------------------------------------------------------------------------------------------
      Learning rate decreased.
---------------------------------------------------------------------------------------------------
| epoch  30 |     1/    3 batches | ms/batch 2345.25 | loss 87784.03 |
Variable containing:
(  0  ,.,.) = 
  0.2575  0.2558  0.2457  0.2409
  0.2443  0.2541  0.2527  0.2489
  0.2485  0.2498  0.2503  0.2514
               ⋮                
  0.2464  0.2498  0.2521  0.2517
  0.2463  0.2518  0.2498  0.2522
  0.2526  0.2475  0.2487  0.2513

(  1  ,.,.) = 
  0.2679  0.2841  0.2791  0.1688
  0.2445  0.2402  0.2422  0.2731
  0.2464  0.2452  0.2475  0.2609
               ⋮                
  0.2430  0.2390  0.2403  0.2778
  0.2436  0.2413  0.2431  0.2721
  0.2503  0.2491  0.2482  0.2524

(  2  ,.,.) = 
  0.2669  0.2497  0.2561  0.2274
  0.2429  0.2533  0.2486  0.2552
  0.2484  0.2518  0.2480  0.2518
               ⋮                
  0.2436  0.2515  0.2484  0.2565
  0.2463  0.2526  0.2478  0.2532
  0.2503  0.2484  0.2501  0.2511

(  3  ,.,.) = 
  0.2432  0.2075  0.3034  0.2460
  0.2499  0.2593  0.2388  0.2520
  0.2544  0.2538  0.2412  0.2506
               ⋮                
  0.2508  0.2626  0.2356  0.2510
  0.2544  0.2586  0.2352  0.2517
  0.2486  0.2523  0.2492  0.2499
[torch.FloatTensor of size 4x30000x4]

| epoch  30 |     2/    3 batches | ms/batch 2448.29 | loss 97026.79 |
Variable containing:
(  0  ,.,.) = 
  0.0915  0.3257  0.3000  0.2828
  0.3114  0.2315  0.2288  0.2284
  0.2709  0.2412  0.2445  0.2435
               ⋮                
  0.3319  0.2193  0.2226  0.2262
  0.3036  0.2316  0.2319  0.2329
  0.2644  0.2415  0.2443  0.2498

(  1  ,.,.) = 
  0.5020  0.2615  0.1391  0.0973
  0.1982  0.2254  0.2731  0.3034
  0.2274  0.2451  0.2591  0.2684
               ⋮                
  0.1842  0.2245  0.2779  0.3133
  0.2053  0.2324  0.2647  0.2976
  0.2368  0.2483  0.2544  0.2605

(  2  ,.,.) = 
  0.2077  0.2739  0.2519  0.2665
  0.2618  0.2450  0.2457  0.2475
  0.2566  0.2461  0.2481  0.2491
               ⋮                
  0.2651  0.2415  0.2473  0.2461
  0.2625  0.2431  0.2448  0.2495
  0.2524  0.2482  0.2497  0.2497

(  3  ,.,.) = 
  0.1811  0.2092  0.3139  0.2959
  0.2784  0.2564  0.2351  0.2300
  0.2635  0.2533  0.2421  0.2410
               ⋮                
  0.2779  0.2620  0.2293  0.2308
  0.2747  0.2550  0.2367  0.2337
  0.2498  0.2522  0.2471  0.2509
[torch.FloatTensor of size 4x30000x4]

| epoch  30 |     3/    3 batches | ms/batch 2499.58 | loss 90197.39 |
Variable containing:
(  0  ,.,.) = 
  0.2555  0.2581  0.2334  0.2530
  0.2480  0.2501  0.2455  0.2564
  0.2504  0.2486  0.2485  0.2525
               ⋮                
  0.2483  0.2484  0.2522  0.2511
  0.2478  0.2484  0.2477  0.2562
  0.2499  0.2488  0.2548  0.2465

(  1  ,.,.) = 
  0.2480  0.2464  0.2397  0.2659
  0.2477  0.2548  0.2582  0.2393
  0.2494  0.2506  0.2515  0.2485
               ⋮                
  0.2498  0.2527  0.2547  0.2428
  0.2486  0.2532  0.2557  0.2425
  0.2515  0.2481  0.2468  0.2536

(  2  ,.,.) = 
  0.2662  0.2721  0.2494  0.2123
  0.2481  0.2554  0.2479  0.2486
  0.2503  0.2499  0.2518  0.2479
               ⋮                
  0.2454  0.2469  0.2492  0.2586
  0.2501  0.2527  0.2515  0.2458
  0.2494  0.2461  0.2501  0.2544

(  3  ,.,.) = 
  0.2678  0.2369  0.2477  0.2476
  0.2512  0.2501  0.2521  0.2467
  0.2496  0.2495  0.2515  0.2494
               ⋮                
  0.2467  0.2525  0.2518  0.2490
  0.2500  0.2498  0.2521  0.2480
  0.2484  0.2515  0.2490  0.2511
[torch.FloatTensor of size 4x30000x4]

---------------------------------------------------------------------------------------------------
    | end of training epoch  30 | time:  7.67s | training loss 90197.39 |
    | end of validation epoch  30 | time:  1.35s | validation loss 52272.92 |
---------------------------------------------------------------------------------------------------
      Learning rate decreased.
---------------------------------------------------------------------------------------------------
| epoch  31 |     1/    3 batches | ms/batch 2872.19 | loss 96338.63 |
| epoch  31 |     2/    3 batches | ms/batch 2645.66 | loss 90681.52 |
| epoch  31 |     3/    3 batches | ms/batch 2561.89 | loss 89936.46 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  31 | time:  7.69s | training loss 89936.46 |
    | end of validation epoch  31 | time:  1.23s | validation loss 51479.88 |
---------------------------------------------------------------------------------------------------
      Best validation model found and saved.
---------------------------------------------------------------------------------------------------
      Learning rate decreased.
---------------------------------------------------------------------------------------------------
| epoch  32 |     1/    3 batches | ms/batch 2483.47 | loss 88658.43 |
| epoch  32 |     2/    3 batches | ms/batch 2481.21 | loss 100301.73 |
| epoch  32 |     3/    3 batches | ms/batch 2479.82 | loss 89658.36 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  32 | time:  7.44s | training loss 89658.36 |
    | end of validation epoch  32 | time:  1.38s | validation loss 51553.16 |
---------------------------------------------------------------------------------------------------
      Learning rate decreased.
---------------------------------------------------------------------------------------------------
| epoch  33 |     1/    3 batches | ms/batch 3950.75 | loss 86273.14 |
| epoch  33 |     2/    3 batches | ms/batch 3474.76 | loss 85432.49 |
| epoch  33 |     3/    3 batches | ms/batch 3315.26 | loss 89595.74 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  33 | time:  9.95s | training loss 89595.74 |
    | end of validation epoch  33 | time:  1.29s | validation loss 51529.94 |
---------------------------------------------------------------------------------------------------
      Learning rate decreased.
---------------------------------------------------------------------------------------------------
| epoch  34 |     1/    3 batches | ms/batch 2384.46 | loss 107980.05 |
| epoch  34 |     2/    3 batches | ms/batch 2370.10 | loss 101270.81 |
| epoch  34 |     3/    3 batches | ms/batch 2396.12 | loss 89544.68 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  34 | time:  7.19s | training loss 89544.68 |
    | end of validation epoch  34 | time:  1.27s | validation loss 51525.23 |
---------------------------------------------------------------------------------------------------
      Learning rate decreased.
---------------------------------------------------------------------------------------------------
| epoch  35 |     1/    3 batches | ms/batch 2354.64 | loss 114663.81 |
| epoch  35 |     2/    3 batches | ms/batch 2442.57 | loss 90773.84 |
| epoch  35 |     3/    3 batches | ms/batch 2803.75 | loss 89520.90 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  35 | time:  8.41s | training loss 89520.90 |
    | end of validation epoch  35 | time:  1.29s | validation loss 51517.47 |
---------------------------------------------------------------------------------------------------
      Learning rate decreased.
---------------------------------------------------------------------------------------------------
| epoch  36 |     1/    3 batches | ms/batch 2796.41 | loss 105985.53 |
| epoch  36 |     2/    3 batches | ms/batch 2619.44 | loss 96916.15 |
| epoch  36 |     3/    3 batches | ms/batch 2550.98 | loss 89510.50 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  36 | time:  7.65s | training loss 89510.50 |
    | end of validation epoch  36 | time:  1.29s | validation loss 51512.87 |
---------------------------------------------------------------------------------------------------
      Learning rate decreased.
---------------------------------------------------------------------------------------------------
| epoch  37 |     1/    3 batches | ms/batch 2401.12 | loss 79037.92 |
| epoch  37 |     2/    3 batches | ms/batch 2403.60 | loss 92047.05 |
| epoch  37 |     3/    3 batches | ms/batch 2392.14 | loss 89506.50 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  37 | time:  7.18s | training loss 89506.50 |
    | end of validation epoch  37 | time:  1.23s | validation loss 51511.64 |
---------------------------------------------------------------------------------------------------
      Learning rate decreased.
---------------------------------------------------------------------------------------------------
| epoch  38 |     1/    3 batches | ms/batch 2364.15 | loss 87841.05 |
| epoch  38 |     2/    3 batches | ms/batch 2559.65 | loss 83198.73 |
| epoch  38 |     3/    3 batches | ms/batch 2773.77 | loss 89503.76 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  38 | time:  8.32s | training loss 89503.76 |
    | end of validation epoch  38 | time:  1.51s | validation loss 51511.31 |
---------------------------------------------------------------------------------------------------
      Learning rate decreased.
---------------------------------------------------------------------------------------------------
| epoch  39 |     1/    3 batches | ms/batch 3315.36 | loss 90851.92 |
| epoch  39 |     2/    3 batches | ms/batch 3107.63 | loss 81555.34 |
| epoch  39 |     3/    3 batches | ms/batch 2834.13 | loss 89502.50 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  39 | time:  8.50s | training loss 89502.50 |
    | end of validation epoch  39 | time:  1.24s | validation loss 51510.66 |
---------------------------------------------------------------------------------------------------
      Learning rate decreased.
---------------------------------------------------------------------------------------------------
| epoch  40 |     1/    3 batches | ms/batch 2351.99 | loss 81616.02 |
Variable containing:
(  0  ,.,.) = 
  0.4178  0.2786  0.1783  0.1253
  0.2358  0.2324  0.2567  0.2750
  0.2299  0.2450  0.2567  0.2684
               ⋮                
  0.2195  0.2345  0.2616  0.2844
  0.2029  0.2275  0.2617  0.3079
  0.2424  0.2524  0.2512  0.2540

(  1  ,.,.) = 
  0.2841  0.2402  0.2537  0.2220
  0.2345  0.2609  0.2508  0.2539
  0.2467  0.2560  0.2468  0.2505
               ⋮                
  0.2386  0.2559  0.2491  0.2565
  0.2378  0.2591  0.2472  0.2559
  0.2532  0.2461  0.2499  0.2509

(  2  ,.,.) = 
  0.2851  0.2364  0.2315  0.2470
  0.2307  0.2678  0.2603  0.2412
  0.2442  0.2516  0.2514  0.2527
               ⋮                
  0.2388  0.2572  0.2568  0.2472
  0.2342  0.2598  0.2544  0.2516
  0.2566  0.2429  0.2464  0.2541

(  3  ,.,.) = 
  0.2735  0.2324  0.2428  0.2512
  0.2540  0.2487  0.2555  0.2418
  0.2503  0.2486  0.2535  0.2477
               ⋮                
  0.2474  0.2523  0.2543  0.2460
  0.2495  0.2503  0.2557  0.2444
  0.2469  0.2524  0.2481  0.2526
[torch.FloatTensor of size 4x30000x4]

| epoch  40 |     2/    3 batches | ms/batch 2430.79 | loss 91150.23 |
Variable containing:
(  0  ,.,.) = 
  0.2661  0.2678  0.2412  0.2250
  0.2490  0.2679  0.2483  0.2347
  0.2527  0.2535  0.2545  0.2392
               ⋮                
  0.2468  0.2523  0.2512  0.2497
  0.2516  0.2590  0.2557  0.2337
  0.2485  0.2420  0.2502  0.2593

(  1  ,.,.) = 
  0.2728  0.2949  0.2805  0.1519
  0.2462  0.2392  0.2451  0.2695
  0.2435  0.2419  0.2486  0.2660
               ⋮                
  0.2428  0.2383  0.2414  0.2775
  0.2367  0.2312  0.2372  0.2949
  0.2503  0.2492  0.2470  0.2534

(  2  ,.,.) = 
  0.2402  0.1998  0.3199  0.2400
  0.2481  0.2541  0.2416  0.2561
  0.2612  0.2535  0.2337  0.2517
               ⋮                
  0.2508  0.2597  0.2364  0.2531
  0.2589  0.2642  0.2221  0.2548
  0.2486  0.2545  0.2481  0.2488

(  3  ,.,.) = 
  0.1785  0.2259  0.2936  0.3019
  0.2767  0.2472  0.2461  0.2300
  0.2678  0.2519  0.2421  0.2381
               ⋮                
  0.2733  0.2530  0.2398  0.2339
  0.2876  0.2515  0.2357  0.2252
  0.2453  0.2515  0.2487  0.2545
[torch.FloatTensor of size 4x30000x4]

| epoch  40 |     3/    3 batches | ms/batch 2440.09 | loss 89501.91 |
Variable containing:
(  0  ,.,.) = 
  0.2176  0.2749  0.2577  0.2499
  0.2540  0.2476  0.2439  0.2545
  0.2571  0.2450  0.2468  0.2511
               ⋮                
  0.2576  0.2434  0.2463  0.2527
  0.2641  0.2398  0.2413  0.2548
  0.2509  0.2486  0.2504  0.2500

(  1  ,.,.) = 
  0.1234  0.2989  0.2906  0.2871
  0.2694  0.2536  0.2421  0.2349
  0.2682  0.2435  0.2452  0.2430
               ⋮                
  0.2863  0.2396  0.2378  0.2363
  0.3072  0.2343  0.2297  0.2289
  0.2577  0.2426  0.2470  0.2527

(  2  ,.,.) = 
  0.2501  0.2366  0.2235  0.2899
  0.2432  0.2622  0.2701  0.2244
  0.2479  0.2526  0.2557  0.2437
               ⋮                
  0.2478  0.2570  0.2611  0.2341
  0.2452  0.2594  0.2670  0.2285
  0.2530  0.2460  0.2433  0.2578

(  3  ,.,.) = 
  0.2651  0.2631  0.2356  0.2361
  0.2441  0.2507  0.2359  0.2693
  0.2496  0.2475  0.2442  0.2587
               ⋮                
  0.2466  0.2478  0.2472  0.2584
  0.2423  0.2456  0.2423  0.2698
  0.2506  0.2480  0.2589  0.2424
[torch.FloatTensor of size 4x30000x4]

---------------------------------------------------------------------------------------------------
    | end of training epoch  40 | time:  7.47s | training loss 89501.91 |
    | end of validation epoch  40 | time:  1.23s | validation loss 51510.45 |
---------------------------------------------------------------------------------------------------
      Learning rate decreased.
---------------------------------------------------------------------------------------------------
| epoch  41 |     1/    3 batches | ms/batch 2343.58 | loss 62769.04 |
| epoch  41 |     2/    3 batches | ms/batch 2378.88 | loss 85479.37 |
| epoch  41 |     3/    3 batches | ms/batch 2362.41 | loss 89501.58 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  41 | time:  7.09s | training loss 89501.58 |
    | end of validation epoch  41 | time:  1.28s | validation loss 51510.35 |
---------------------------------------------------------------------------------------------------
      Learning rate decreased.
---------------------------------------------------------------------------------------------------
| epoch  42 |     1/    3 batches | ms/batch 2398.59 | loss 77296.59 |
| epoch  42 |     2/    3 batches | ms/batch 2329.13 | loss 87299.64 |
| epoch  42 |     3/    3 batches | ms/batch 2307.64 | loss 89501.42 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  42 | time:  6.92s | training loss 89501.42 |
    | end of validation epoch  42 | time:  1.27s | validation loss 51510.30 |
---------------------------------------------------------------------------------------------------
      Learning rate decreased.
---------------------------------------------------------------------------------------------------
| epoch  43 |     1/    3 batches | ms/batch 2436.09 | loss 84322.12 |
| epoch  43 |     2/    3 batches | ms/batch 2453.96 | loss 85892.17 |
| epoch  43 |     3/    3 batches | ms/batch 2464.46 | loss 89501.34 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  43 | time:  7.39s | training loss 89501.34 |
    | end of validation epoch  43 | time:  1.30s | validation loss 51510.27 |
---------------------------------------------------------------------------------------------------
      Learning rate decreased.
---------------------------------------------------------------------------------------------------
| epoch  44 |     1/    3 batches | ms/batch 2399.34 | loss 83739.14 |
| epoch  44 |     2/    3 batches | ms/batch 2378.54 | loss 91800.11 |
| epoch  44 |     3/    3 batches | ms/batch 2384.61 | loss 89501.30 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  44 | time:  7.15s | training loss 89501.30 |
    | end of validation epoch  44 | time:  1.36s | validation loss 51510.27 |
---------------------------------------------------------------------------------------------------
      Learning rate decreased.
---------------------------------------------------------------------------------------------------
| epoch  45 |     1/    3 batches | ms/batch 2926.42 | loss 77643.27 |
| epoch  45 |     2/    3 batches | ms/batch 2641.83 | loss 79113.98 |
| epoch  45 |     3/    3 batches | ms/batch 2561.40 | loss 89501.28 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  45 | time:  7.68s | training loss 89501.28 |
    | end of validation epoch  45 | time:  1.31s | validation loss 51510.27 |
---------------------------------------------------------------------------------------------------
      Learning rate decreased.
---------------------------------------------------------------------------------------------------
| epoch  46 |     1/    3 batches | ms/batch 2322.69 | loss 86781.34 |
| epoch  46 |     2/    3 batches | ms/batch 2317.97 | loss 93850.04 |
| epoch  46 |     3/    3 batches | ms/batch 2335.73 | loss 89501.27 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  46 | time:  7.01s | training loss 89501.27 |
    | end of validation epoch  46 | time:  1.29s | validation loss 51510.27 |
---------------------------------------------------------------------------------------------------
      Learning rate decreased.
---------------------------------------------------------------------------------------------------
| epoch  47 |     1/    3 batches | ms/batch 2435.70 | loss 78022.88 |
| epoch  47 |     2/    3 batches | ms/batch 2407.68 | loss 87378.51 |
| epoch  47 |     3/    3 batches | ms/batch 2402.15 | loss 89501.27 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  47 | time:  7.21s | training loss 89501.27 |
    | end of validation epoch  47 | time:  1.28s | validation loss 51510.27 |
---------------------------------------------------------------------------------------------------
      Learning rate decreased.
---------------------------------------------------------------------------------------------------
| epoch  48 |     1/    3 batches | ms/batch 2405.31 | loss 78791.38 |
| epoch  48 |     2/    3 batches | ms/batch 2394.59 | loss 89159.63 |
| epoch  48 |     3/    3 batches | ms/batch 2364.04 | loss 89501.27 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  48 | time:  7.09s | training loss 89501.27 |
    | end of validation epoch  48 | time:  1.26s | validation loss 51510.27 |
---------------------------------------------------------------------------------------------------
      Learning rate decreased.
---------------------------------------------------------------------------------------------------
| epoch  49 |     1/    3 batches | ms/batch 2325.93 | loss 93415.59 |
| epoch  49 |     2/    3 batches | ms/batch 2389.25 | loss 85661.21 |
| epoch  49 |     3/    3 batches | ms/batch 2418.16 | loss 89501.26 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  49 | time:  7.25s | training loss 89501.26 |
    | end of validation epoch  49 | time:  1.28s | validation loss 51510.27 |
---------------------------------------------------------------------------------------------------
      Learning rate decreased.
---------------------------------------------------------------------------------------------------
| epoch  50 |     1/    3 batches | ms/batch 2439.97 | loss 84898.99 |
Variable containing:
(  0  ,.,.) = 
  0.1785  0.2259  0.2936  0.3020
  0.2767  0.2472  0.2461  0.2300
  0.2678  0.2519  0.2421  0.2381
               ⋮                
  0.2733  0.2530  0.2398  0.2339
  0.2877  0.2515  0.2357  0.2252
  0.2453  0.2515  0.2487  0.2545

(  1  ,.,.) = 
  0.2728  0.2949  0.2805  0.1519
  0.2462  0.2392  0.2452  0.2695
  0.2435  0.2419  0.2486  0.2660
               ⋮                
  0.2428  0.2383  0.2414  0.2775
  0.2367  0.2312  0.2372  0.2949
  0.2503  0.2492  0.2470  0.2535

(  2  ,.,.) = 
  0.2501  0.2365  0.2235  0.2899
  0.2432  0.2622  0.2702  0.2244
  0.2479  0.2526  0.2558  0.2437
               ⋮                
  0.2478  0.2570  0.2611  0.2341
  0.2452  0.2594  0.2670  0.2285
  0.2530  0.2460  0.2432  0.2578

(  3  ,.,.) = 
  0.2661  0.2677  0.2412  0.2251
  0.2491  0.2679  0.2483  0.2347
  0.2528  0.2535  0.2545  0.2392
               ⋮                
  0.2468  0.2524  0.2512  0.2497
  0.2516  0.2591  0.2557  0.2336
  0.2485  0.2420  0.2502  0.2594
[torch.FloatTensor of size 4x30000x4]

| epoch  50 |     2/    3 batches | ms/batch 2550.29 | loss 89991.98 |
Variable containing:
(  0  ,.,.) = 
  0.2652  0.2631  0.2356  0.2361
  0.2441  0.2507  0.2359  0.2693
  0.2496  0.2475  0.2442  0.2587
               ⋮                
  0.2466  0.2478  0.2472  0.2584
  0.2423  0.2456  0.2422  0.2698
  0.2506  0.2480  0.2589  0.2424

(  1  ,.,.) = 
  0.4179  0.2786  0.1783  0.1252
  0.2359  0.2324  0.2567  0.2750
  0.2299  0.2450  0.2567  0.2684
               ⋮                
  0.2195  0.2345  0.2616  0.2844
  0.2028  0.2275  0.2617  0.3080
  0.2423  0.2524  0.2513  0.2540

(  2  ,.,.) = 
  0.1233  0.2989  0.2907  0.2871
  0.2694  0.2536  0.2421  0.2349
  0.2682  0.2435  0.2452  0.2430
               ⋮                
  0.2863  0.2396  0.2378  0.2363
  0.3073  0.2343  0.2296  0.2288
  0.2577  0.2426  0.2470  0.2527

(  3  ,.,.) = 
  0.2175  0.2749  0.2577  0.2499
  0.2540  0.2476  0.2439  0.2545
  0.2571  0.2450  0.2468  0.2511
               ⋮                
  0.2576  0.2434  0.2463  0.2527
  0.2641  0.2398  0.2413  0.2548
  0.2509  0.2486  0.2504  0.2500
[torch.FloatTensor of size 4x30000x4]

| epoch  50 |     3/    3 batches | ms/batch 2565.87 | loss 89501.26 |
Variable containing:
(  0  ,.,.) = 
  0.2735  0.2324  0.2428  0.2512
  0.2540  0.2487  0.2555  0.2418
  0.2503  0.2486  0.2535  0.2477
               ⋮                
  0.2474  0.2523  0.2543  0.2460
  0.2495  0.2503  0.2557  0.2444
  0.2469  0.2524  0.2480  0.2526

(  1  ,.,.) = 
  0.2841  0.2402  0.2537  0.2220
  0.2344  0.2609  0.2508  0.2539
  0.2467  0.2560  0.2468  0.2505
               ⋮                
  0.2386  0.2559  0.2491  0.2565
  0.2378  0.2591  0.2472  0.2559
  0.2532  0.2461  0.2499  0.2509

(  2  ,.,.) = 
  0.2851  0.2364  0.2315  0.2470
  0.2307  0.2679  0.2603  0.2411
  0.2442  0.2517  0.2514  0.2527
               ⋮                
  0.2388  0.2572  0.2568  0.2472
  0.2342  0.2598  0.2545  0.2516
  0.2566  0.2429  0.2464  0.2541

(  3  ,.,.) = 
  0.2402  0.1998  0.3199  0.2400
  0.2481  0.2541  0.2416  0.2561
  0.2612  0.2535  0.2337  0.2517
               ⋮                
  0.2508  0.2597  0.2364  0.2531
  0.2589  0.2642  0.2221  0.2548
  0.2486  0.2545  0.2481  0.2488
[torch.FloatTensor of size 4x30000x4]

---------------------------------------------------------------------------------------------------
    | end of training epoch  50 | time:  7.86s | training loss 89501.26 |
    | end of validation epoch  50 | time:  1.30s | validation loss 51510.27 |
---------------------------------------------------------------------------------------------------
      Learning rate decreased.
---------------------------------------------------------------------------------------------------
| epoch  51 |     1/    3 batches | ms/batch 2725.71 | loss 91311.64 |
| epoch  51 |     2/    3 batches | ms/batch 2732.25 | loss 88578.70 |
| epoch  51 |     3/    3 batches | ms/batch 2631.03 | loss 89501.26 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  51 | time:  7.89s | training loss 89501.26 |
    | end of validation epoch  51 | time:  1.23s | validation loss 51510.27 |
---------------------------------------------------------------------------------------------------
      Learning rate decreased.
---------------------------------------------------------------------------------------------------
| epoch  52 |     1/    3 batches | ms/batch 2415.58 | loss 93445.84 |
| epoch  52 |     2/    3 batches | ms/batch 2424.88 | loss 78336.73 |
| epoch  52 |     3/    3 batches | ms/batch 2416.65 | loss 89501.27 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  52 | time:  7.25s | training loss 89501.27 |
    | end of validation epoch  52 | time:  1.24s | validation loss 51510.27 |
---------------------------------------------------------------------------------------------------
      Learning rate decreased.
---------------------------------------------------------------------------------------------------
| epoch  53 |     1/    3 batches | ms/batch 2455.93 | loss 91344.45 |
| epoch  53 |     2/    3 batches | ms/batch 2796.60 | loss 88883.94 |
| epoch  53 |     3/    3 batches | ms/batch 2872.36 | loss 89501.26 |
---------------------------------------------------------------------------------------------------
    | end of training epoch  53 | time:  8.62s | training loss 89501.26 |
    | end of validation epoch  53 | time:  1.37s | validation loss 51510.27 |
---------------------------------------------------------------------------------------------------
      Learning rate decreased.
---------------------------------------------------------------------------------------------------
^Z
[1]+  Stopped                 python danet-softmax-small.py
shutian@shutian-virtual-machine:~/Desktop/Project/code$ 

